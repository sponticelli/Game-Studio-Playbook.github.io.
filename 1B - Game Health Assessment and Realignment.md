---
layout: default
title: "Game Health Assessment and Realignment"
---

# Game Health Assessment & Realignment

## For Mature Games & Live Operations

> *"Successful liveOps is only possible when the core gameplay has good retention by itself. It is not a support costâ€”it is almost a full development team with ongoing traffic acquisition."*

---

## When to Use This Block

Use Track B (this block) instead of Track A if:

- [ ] Your game has been live for 1+ years
- [ ] You have meaningful historical data to analyze
- [ ] The team inherited the project or has significant turnover
- [ ] You're questioning whether current direction is right
- [ ] Maintenance burden is crowding out new development
- [ ] Metrics are declining or plateauing
- [ ] You're considering a major update, pivot, or sunset

**This block is an audit and realignment exercise.** Complete it before planning your next major initiative.

---

## How to Use This Block

**Recommended cadence:** Complete this audit quarterly for live games, or whenever considering major strategic shifts.

---

# 1B.1 Vision Drift Assessment

## Why It Matters

Games evolve. Over years, countless features, events, and pivots accumulate. The game players experience today may bear little resemblance to the original visionâ€”sometimes for better, sometimes for worse. Understanding where you've drifted helps you decide: return to the original vision, embrace the evolution, or consciously chart a new direction.

## Framework: Vision Archaeology

### Step 1: Reconstruct the Original Vision

*What was this game supposed to be when it launched?*

| Element | Original Vision (Launch) | Source |
|---------|-------------------------|--------|
| Core fantasy | | GDD, marketing, interviews |
| Target player | | Launch materials |
| Core loop | | Original design docs |
| Key differentiators | | Press releases, reviews |
| Business model intent | | Internal docs |

### Step 2: Document Current Reality

*What is the game actually doing now?*

| Element | Current Reality | Evidence |
|---------|-----------------|----------|
| Core fantasy delivered | | Player feedback, reviews |
| Who actually plays | | Analytics, demographics |
| What players actually do | | Session data, feature usage |
| What differentiates now | | Competitive analysis |
| How it actually monetizes | | Revenue breakdown |

### Step 3: Identify Drift

| Area | Drift Direction | Intentional? | Positive/Negative? |
|------|-----------------|--------------|-------------------|
| | | Yes / No / Unknown | + / - / Neutral |
| | | | |
| | | | |
| | | | |

## Framework: Vision Drift Quadrant

```
                    Intentional Drift
                          â”‚
           EVOLVED        â”‚        PIVOTED
        (Planned growth)  â”‚    (Strategic shift)
                          â”‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                          â”‚
          DECAYED         â”‚         LOST
      (Quality erosion)   â”‚    (Unplanned drift)
                          â”‚
                   Unintentional Drift
```

**Our game is in quadrant:** _______________

**This means we should:** _______________

## Diagnostic Questions

| Question | Answer | Implication |
|----------|--------|-------------|
| Can new team members articulate what the game is about? | | If no: vision unclear |
| Do veteran players describe the game the way you would? | | If no: perception gap |
| Does the tutorial still reflect the core experience? | | If no: onboarding mismatch |
| Would the original creators recognize this game? | | Drift indicator |
| Are recent features coherent with each other? | | If no: fragmentation |

## Vision Decision Framework

Based on your drift assessment, choose a direction:

| Option | When to Choose | Actions Required |
|--------|----------------|------------------|
| **Return to roots** | Drift was unintentional, original vision still relevant, players miss "old game" | Audit features against original pillars, sunset additions that don't fit |
| **Embrace evolution** | Game has naturally found a better identity, players prefer current state | Document new vision, align future work to evolved identity |
| **Conscious pivot** | Market has shifted, original vision no longer viable, new opportunity identified | Full vision rewrite, major update marketing, may lose some existing players |
| **Maintain course** | Drift is minimal, current direction is working | Document current vision explicitly, use for alignment |

**Our decision:** _______________

## Checklist

- [ ] Original vision documents located and reviewed
- [ ] Current state documented with evidence
- [ ] Drift areas identified and categorized
- [ ] Quadrant placement determined
- [ ] Direction decision made
- [ ] New/updated vision statement drafted (if needed)

## Tasks

1. **Dig up original documents** â€” GDD, pitch decks, launch marketing, early reviews
2. **Interview long-tenured team members** â€” What do they remember as the original intent?
3. **Read 100 recent player reviews** â€” How do players describe your game?
4. **Compare launch trailer to current gameplay** â€” Same game?
5. **Draft a "current vision" statement** â€” What is the game NOW?

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# 1B.2 Current State Metrics Audit

## Why It Matters

Intuition is unreliable for games with years of history. Metrics reveal what's actually happeningâ€”not what you assume or remember. A comprehensive metrics audit surfaces trends, identifies problems, and establishes baselines for measuring improvement.

## Framework: Metrics Health Dashboard

### Retention Trends

| Metric | 12 Months Ago | 6 Months Ago | Current | Trend | Benchmark |
|--------|---------------|--------------|---------|-------|-----------|
| D1 Retention | | | | â†‘â†“â†’ | |
| D7 Retention | | | | â†‘â†“â†’ | |
| D30 Retention | | | | â†‘â†“â†’ | |
| D90 Retention | | | | â†‘â†“â†’ | |
| D365 Retention | | | | â†‘â†“â†’ | |

**Retention diagnosis:**
```
_______________________________________________________________________________
```

### Engagement Trends

| Metric | 12 Months Ago | 6 Months Ago | Current | Trend |
|--------|---------------|--------------|---------|-------|
| DAU | | | | â†‘â†“â†’ |
| MAU | | | | â†‘â†“â†’ |
| DAU/MAU (Stickiness) | | | | â†‘â†“â†’ |
| Avg Session Length | | | | â†‘â†“â†’ |
| Sessions per DAU | | | | â†‘â†“â†’ |
| Days Played per MAU | | | | â†‘â†“â†’ |

**Engagement diagnosis:**
```
_______________________________________________________________________________
```

### Monetization Trends

| Metric | 12 Months Ago | 6 Months Ago | Current | Trend |
|--------|---------------|--------------|---------|-------|
| ARPDAU | | | | â†‘â†“â†’ |
| ARPPU | | | | â†‘â†“â†’ |
| Payer Conversion % | | | | â†‘â†“â†’ |
| Whale Concentration % | | | | â†‘â†“â†’ |
| IAP Revenue % | | | | â†‘â†“â†’ |
| Ad Revenue % | | | | â†‘â†“â†’ |
| LTV (30-day) | | | | â†‘â†“â†’ |
| LTV (lifetime) | | | | â†‘â†“â†’ |

**Monetization diagnosis:**
```
_______________________________________________________________________________
```

### Acquisition Trends

| Metric | 12 Months Ago | 6 Months Ago | Current | Trend |
|--------|---------------|--------------|---------|-------|
| Daily Installs | | | | â†‘â†“â†’ |
| Organic % | | | | â†‘â†“â†’ |
| CPI (blended) | | | | â†‘â†“â†’ |
| CPI (by channel) | | | | â†‘â†“â†’ |
| ROAS D7 | | | | â†‘â†“â†’ |
| ROAS D30 | | | | â†‘â†“â†’ |

**Acquisition diagnosis:**
```
_______________________________________________________________________________
```

## Framework: Cohort Quality Comparison

Compare cohort behavior over timeâ€”are new users better or worse than old ones?

| Cohort | D1 Ret | D7 Ret | D30 Ret | D7 ARPU | Payer Conv |
|--------|--------|--------|---------|---------|------------|
| 2 years ago | | | | | |
| 1 year ago | | | | | |
| 6 months ago | | | | | |
| 3 months ago | | | | | |
| Last month | | | | | |

**Cohort quality trend:** Improving / Stable / Declining

**Hypothesis for trend:**
```
_______________________________________________________________________________
```

## Framework: Red Flag Identification

| Red Flag | Threshold | Your Status | Action Required |
|----------|-----------|-------------|-----------------|
| D1 retention declining | >5% drop YoY | | FTUE audit |
| DAU/MAU below 20% | <0.20 | | Engagement audit |
| Whale concentration >50% | >50% revenue from <1% users | | Revenue diversification |
| Organic % below 20% | <20% | | ASO, virality audit |
| LTV < CPI | Negative unit economics | | Monetization or UA overhaul |
| Payer conversion declining | >20% drop YoY | | Economy audit |
| Session length declining | >15% drop YoY | | Content/engagement audit |

## Diagnostic Questions

| Question | Answer | Implication |
|----------|--------|-------------|
| Are we comparing to relevant benchmarks (genre, age)? | | Old games have different benchmarks |
| Do we understand WHY metrics are moving? | | Correlation â‰  causation |
| Are we tracking the right things? | | Missing metrics = blind spots |
| How reliable is our data? | | Bad data = bad decisions |
| What would "good" look like for a game our age? | | Expectations must be realistic |

## Checklist

- [ ] All core metrics pulled for 12+ month trend
- [ ] Cohort comparison completed
- [ ] Benchmarks identified for game age and genre
- [ ] Red flags identified
- [ ] Trends explained (not just observed)
- [ ] Data quality verified

## Tasks

1. **Pull comprehensive metrics export** for last 24 months
2. **Create trend visualizations** for key metrics
3. **Identify the 3 most concerning trends** â€” Why are they happening?
4. **Identify the 3 healthiest metrics** â€” What's working?
5. **Compare to genre benchmarks** (adjust for game age)

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# 1B.3 Audience Evolution Analysis

## Why It Matters

Your players today may be very different from your launch audience. Demographics shift, early adopters churn, new segments discover the game. Understanding who actually playsâ€”and who you're losingâ€”informs feature priorities, content tone, and marketing targeting.

## Framework: Audience Snapshot Comparison

### Who We Designed For vs. Who Plays Now

| Attribute | Original Target (Launch) | Current Reality | Delta |
|-----------|-------------------------|-----------------|-------|
| Age range | | | |
| Gender split | | | |
| Geography | | | |
| Platform | | | |
| Play session length | | | |
| Spending level | | | |
| Gaming experience | | | |

### Player Segment Evolution

| Segment | % at Launch | % Now | Trend | Value (ARPU) |
|---------|-------------|-------|-------|--------------|
| Hardcore enthusiasts | | | â†‘â†“â†’ | |
| Regular engaged | | | â†‘â†“â†’ | |
| Casual/light | | | â†‘â†“â†’ | |
| Returning/lapsed | | | â†‘â†“â†’ | |
| New (< 30 days) | | | â†‘â†“â†’ | |

## Framework: Cohort Persona Analysis

### Long-Tenured Players (2+ years)

| Question | Finding |
|----------|---------|
| What % of DAU are they? | |
| What % of revenue? | |
| What features do they use most? | |
| What do they complain about? | |
| What keeps them playing? | |
| What would make them leave? | |

### Mid-Tenure Players (6 months - 2 years)

| Question | Finding |
|----------|---------|
| What % of DAU are they? | |
| What % of revenue? | |
| What features do they use most? | |
| What's their engagement pattern? | |
| Are they deepening or plateauing? | |

### New Players (< 6 months)

| Question | Finding |
|----------|---------|
| What % of DAU are they? | |
| What's their retention vs. historical? | |
| Where do they come from? | |
| What's their first-week experience? | |
| Where do they drop off? | |

## Framework: Churn Analysis

### Who Are We Losing?

| Churned Segment | Tenure at Churn | Last Active Feature | Likely Reason | Winback Potential |
|-----------------|-----------------|--------------------|--------------|--------------------|
| | | | | High / Medium / Low |
| | | | | |
| | | | | |

### Exit Survey / Review Analysis

*Common themes from churned players (reviews, surveys, support tickets):*

| Theme | Frequency | Addressable? |
|-------|-----------|--------------|
| | | Yes / No / Partially |
| | | |
| | | |
| | | |

## Diagnostic Questions

| Question | Answer | Implication |
|----------|--------|-------------|
| Is our audience getting older with the game? | | May need to attract new blood |
| Are high-value players churning faster than before? | | Revenue risk |
| Does new player experience match current audience expectations? | | FTUE may be outdated |
| Are we marketing to who we have or who we want? | | Targeting alignment |
| Do community voices represent the silent majority? | | Vocal minority risk |

## Framework: Audience Strategy Decision

| Situation | Strategy Options |
|-----------|------------------|
| Core audience aging, shrinking | Attract new segments OR graceful decline plan |
| New players not sticking | FTUE overhaul, content pacing adjustment |
| High-value players churning | VIP retention program, exclusive content |
| Wrong audience finding the game | UA targeting adjustment, positioning clarity |
| Audience healthier than expected | Double down on what's working |

**Our situation:** _______________

**Our strategy:** _______________

## Checklist

- [ ] Demographic data pulled and compared to launch
- [ ] Player segments defined and sized
- [ ] Cohort behaviors analyzed by tenure
- [ ] Churn patterns identified
- [ ] Exit feedback analyzed
- [ ] Audience strategy chosen

## Tasks

1. **Pull demographic data** from analytics, surveys, platform dashboards
2. **Segment your DAU** by tenure and analyze each group
3. **Review 50 negative reviews** from last 6 months â€” who's complaining?
4. **Analyze your best players** â€” what makes them stay?
5. **Compare UA targeting to actual audience** â€” mismatch?

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# 1B.4 Feature Usage Audit

## Why It Matters

Mature games accumulate features like houses accumulate stuff. Each feature has ongoing costs: bug fixes, balance updates, QA coverage, localization, documentation, new player confusion. Features that few players use drain capacity from improvements that would matter more. Regular audits identify what to invest in, what to simplify, and what to sunset.

## Framework: Feature Inventory

List all major features and systems in your game:

| # | Feature/System | Launch Feature? | Last Major Update | Owner |
|---|----------------|-----------------|-------------------|-------|
| 1 | | Yes / No | | |
| 2 | | Yes / No | | |
| 3 | | Yes / No | | |
| 4 | | Yes / No | | |
| 5 | | Yes / No | | |
| 6 | | Yes / No | | |
| 7 | | Yes / No | | |
| 8 | | Yes / No | | |
| 9 | | Yes / No | | |
| 10 | | Yes / No | | |
| 11 | | Yes / No | | |
| 12 | | Yes / No | | |
| 13 | | Yes / No | | |
| 14 | | Yes / No | | |
| 15 | | Yes / No | | |

## Framework: Feature Health Matrix

For each feature, assess:

| Feature | DAU % Using | Revenue Impact | Maint. Cost | Strategic Value | Health Score |
|---------|-------------|----------------|-------------|-----------------|--------------|
| | High/Med/Low | High/Med/Low | High/Med/Low | Core/Support/Legacy | |
| | | | | | |
| | | | | | |
| | | | | | |
| | | | | | |

**Health Score Calculation:**
- Usage: High=3, Med=2, Low=1
- Revenue: High=3, Med=2, Low=1
- Maintenance: High=1, Med=2, Low=3 (invertedâ€”low cost is good)
- Strategic: Core=3, Support=2, Legacy=1
- **Total: /12**

## Framework: Feature Quadrant Analysis

```
                     High Usage
                         â”‚
        CORE            â”‚           OPTIMIZE
   (Protect & enhance)   â”‚    (High value, high costâ€”
                         â”‚     simplify or invest)
                         â”‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                         â”‚
        REVIEW           â”‚           SUNSET
   (Low usage but may    â”‚    (Low value, any costâ€”
    have strategic value)â”‚     remove or archive)
                         â”‚
                     Low Usage

    â—„â”€â”€â”€ Low Maintenance Cost â”€â”€â”€â”€â”€â”€â”€â”€â”€ High Maintenance Cost â”€â”€â”€â–º
```

### Feature Placement

| Quadrant | Features | Recommended Action |
|----------|----------|--------------------|
| **CORE** | | Protect, enhance, never break |
| **OPTIMIZE** | | Reduce maintenance cost or increase value |
| **REVIEW** | | Investigateâ€”is low usage a discovery problem or disinterest? |
| **SUNSET** | | Remove, archive, or stop maintaining |

## Framework: Feature Dependency Mapping

Before sunsetting, understand dependencies:

| Sunset Candidate | Depends On | Depended On By | Removal Complexity |
|------------------|------------|----------------|-------------------|
| | | | Low / Medium / High |
| | | | |
| | | | |

## Framework: Maintenance Cost Estimation

| Feature | Eng Hours/Month | QA Hours/Month | CS Tickets/Month | Total Monthly Cost |
|---------|-----------------|----------------|------------------|-------------------|
| | | | | |
| | | | | |
| | | | | |
| | | | | |
| **Total** | | | | |

**% of capacity spent on maintenance:** _______________

## Diagnostic Questions

| Question | Answer | Implication |
|----------|--------|-------------|
| What % of features are used by <10% of DAU? | | Bloat indicator |
| What % of capacity goes to maintaining vs. building? | | Velocity indicator |
| When did we last remove a feature? | | Culture indicator |
| Do new players use the same features as veterans? | | Complexity/discovery issue |
| Which features generate the most bugs? | | Technical debt indicator |

## Checklist

- [ ] Complete feature inventory created
- [ ] Usage data pulled for each feature
- [ ] Revenue attribution estimated
- [ ] Maintenance cost estimated
- [ ] Features placed in quadrants
- [ ] Sunset candidates identified
- [ ] Dependencies mapped for candidates

## Tasks

1. **List every feature** â€” be exhaustive, include "small" things
2. **Pull usage data** â€” what % of DAU touches each feature weekly?
3. **Estimate maintenance burden** â€” ask engineers and QA
4. **Place features in quadrants** â€” use data, not intuition
5. **Identify top 3 sunset candidates** â€” present to stakeholders

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# 1B.5 Technical Debt Inventory

## Why It Matters

Technical debt compounds. Systems built quickly 5 years ago become bottlenecks today. Code that "works" may be fragile, slow, or incomprehensible to current team members. Mature games must actively manage tech debt or drown in itâ€”every new feature becomes harder, every bug fix risks breaking something else.

## Framework: Technical Debt Categories

| Category | Description | Examples |
|----------|-------------|----------|
| **Code Debt** | Poor architecture, duplication, no tests | Spaghetti code, copy-paste, missing unit tests |
| **Infrastructure Debt** | Outdated systems, scaling issues | Old server tech, manual deployments, no monitoring |
| **Tool Debt** | Inefficient pipelines, manual processes | No content tools, slow builds, manual config |
| **Documentation Debt** | Missing or outdated docs | No onboarding docs, stale wikis |
| **Dependency Debt** | Outdated SDKs, deprecated APIs | Old Unity version, sunset ad networks |

## Framework: Technical Debt Inventory

| System/Area | Debt Type | Severity | Impact | Remediation Effort | Priority |
|-------------|-----------|----------|--------|-------------------|----------|
| | | Crit/High/Med/Low | | S/M/L/XL | |
| | | | | | |
| | | | | | |
| | | | | | |
| | | | | | |
| | | | | | |
| | | | | | |
| | | | | | |

**Severity Definitions:**
- **Critical:** Actively causing incidents, blocking features, or security risk
- **High:** Significantly slowing development, reliability risk
- **Medium:** Annoying, adds friction, but workable
- **Low:** Suboptimal but not impacting day-to-day

## Framework: Debt Impact Assessment

| Debt Item | Blocks New Features? | Causes Bugs? | Slows Velocity? | Security Risk? | Player-Facing? |
|-----------|---------------------|--------------|-----------------|----------------|----------------|
| | Yes/No | Yes/No | Yes/No | Yes/No | Yes/No |
| | | | | | |
| | | | | | |
| | | | | | |

## Framework: Debt Paydown Prioritization

**Prioritization Matrix:**

```
                     High Impact
                         â”‚
        CRITICAL         â”‚        SCHEDULED
   (Pay down NOWâ€”        â”‚    (Plan for next
    blocking progress)   â”‚     major release)
                         â”‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                         â”‚
        OPPORTUNISTIC    â”‚        TOLERATE
   (Fix when touching    â”‚    (Accept the cost,
    related code)        â”‚     don't prioritize)
                         â”‚
                     Low Impact

    â—„â”€â”€â”€ Low Effort â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ High Effort â”€â”€â”€â–º
```

| Quadrant | Items | Action |
|----------|-------|--------|
| **CRITICAL** | | Immediate sprint allocation |
| **SCHEDULED** | | Roadmap for dedicated paydown |
| **OPPORTUNISTIC** | | Boy Scout ruleâ€”leave better than found |
| **TOLERATE** | | Document and accept |

## Framework: Debt Budget

What % of capacity will you allocate to debt paydown?

| Approach | % of Capacity | When to Use |
|----------|---------------|-------------|
| Crisis mode | 50%+ | Debt actively blocking work |
| Active paydown | 20-30% | High debt, need to improve velocity |
| Maintenance mode | 10-20% | Manageable debt, steady improvement |
| Minimal | <10% | Low debt or accepting decline |

**Our current allocation:** _______________% 

**Our target allocation:** _______________%

## Framework: SDK & Dependency Audit

| Dependency | Current Version | Latest Version | EOL/Deprecated? | Update Urgency |
|------------|-----------------|----------------|-----------------|----------------|
| Game Engine | | | | |
| Analytics SDK | | | | |
| Ad SDK | | | | |
| IAP SDK | | | | |
| Push SDK | | | | |
| Backend/Server | | | | |
| | | | | |

## Diagnostic Questions

| Question | Answer | Implication |
|----------|--------|-------------|
| How long does it take a new engineer to be productive? | | Onboarding friction = debt |
| What's the average age of our dependencies? | | Update risk |
| How often do "simple" changes cause unexpected bugs? | | Architecture debt |
| What areas does no one want to touch? | | Fear = debt |
| How much of the codebase has test coverage? | | Safety net gap |

## Checklist

- [ ] All major systems assessed for debt
- [ ] Debt categorized by type
- [ ] Severity and impact rated
- [ ] Debt placed in priority quadrants
- [ ] Capacity allocation decided
- [ ] SDK/dependency audit completed
- [ ] Debt paydown roadmap drafted

## Tasks

1. **Survey the engineering team** â€” What frustrates them? What's scary to touch?
2. **Review incident history** â€” What systems cause the most fires?
3. **Audit build and deploy times** â€” Where's the friction?
4. **Check dependency versions** â€” What's out of date?
5. **Estimate paydown effort** for top 5 debt items

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# 1B.6 Content Pipeline Efficiency

## Why It Matters

Live games need continuous content to maintain engagement. But content production has real costsâ€”team time, QA, localization, deployment. If your pipeline is inefficient, you either burn out the team, deliver less content, or ship lower quality. Understanding your true capacity prevents overcommitting.

## Framework: Content Velocity Baseline

### Current Content Output

| Content Type | Monthly Output | Team Hours/Unit | Total Hours/Month |
|--------------|----------------|-----------------|-------------------|
| New levels/stages | | | |
| New characters/items | | | |
| Events (major) | | | |
| Events (minor) | | | |
| Offers/promotions | | | |
| Balance updates | | | |
| Bug fixes | | | |
| Localization updates | | | |
| **Total** | | | |

### Capacity vs. Demand

| Metric | Current | Required for KPIs | Gap |
|--------|---------|-------------------|-----|
| Events per month | | | |
| New content pieces per month | | | |
| Update frequency | | | |

## Framework: Pipeline Efficiency Analysis

### Step 1: Map the Pipeline

For your primary content type, map each step:

| Stage | Owner | Avg Duration | Blockers | Automation Level |
|-------|-------|--------------|----------|------------------|
| Concept/Design | | | | None/Partial/Full |
| Asset Creation | | | | |
| Implementation | | | | |
| QA | | | | |
| Localization | | | | |
| Staging/Test | | | | |
| Deployment | | | | |
| **Total Lead Time** | | | | |

### Step 2: Identify Bottlenecks

| Bottleneck | Impact | Root Cause | Potential Solution |
|------------|--------|------------|-------------------|
| | | | |
| | | | |
| | | | |

## Framework: Content Tool Assessment

| Tool/System | Purpose | Efficiency | User Satisfaction | Investment Needed |
|-------------|---------|------------|-------------------|-------------------|
| Level editor | | High/Med/Low | High/Med/Low | |
| Event config tool | | | | |
| Offer management | | | | |
| Balance tuning | | | | |
| Localization system | | | | |
| Remote config | | | | |
| A/B test setup | | | | |

**Tool gaps:**
```
_______________________________________________________________________________
```

## Framework: Sustainable Velocity Calculation

### Current Team Capacity

| Role | People | Hours/Week | Content Hours (vs. maintenance) |
|------|--------|------------|--------------------------------|
| Design | | | |
| Art | | | |
| Engineering | | | |
| QA | | | |
| **Total** | | | |

### Sustainable Output

Based on capacity and pipeline efficiency:

| Content Type | Max Sustainable/Month | Current/Month | Sustainable? |
|--------------|----------------------|---------------|--------------|
| Major events | | | Yes/No |
| Minor events | | | Yes/No |
| New content | | | Yes/No |
| Updates | | | Yes/No |

## Framework: Content Reuse Strategy

| Reuse Approach | Current Usage | Potential |
|----------------|---------------|-----------|
| Template-based events | | |
| Reskinned content | | |
| Community-created content | | |
| Procedural generation | | |
| Seasonal rotation | | |
| Archive revival | | |

## Diagnostic Questions

| Question | Answer | Implication |
|----------|--------|-------------|
| How often do we miss content deadlines? | | Pipeline under stress |
| How much content goes straight to live without issues? | | Quality indicator |
| What's our content planning horizon? | | Can we think ahead? |
| Do we reuse or rebuild from scratch each time? | | Efficiency indicator |
| How much time goes to firefighting vs. planned work? | | Stability indicator |

## Checklist

- [ ] Current content velocity documented
- [ ] Pipeline stages mapped with durations
- [ ] Bottlenecks identified
- [ ] Tool assessment completed
- [ ] Sustainable capacity calculated
- [ ] Gap between demand and capacity quantified
- [ ] Efficiency improvements prioritized

## Tasks

1. **Track actual time** for 3 content pieces end-to-end
2. **Identify the slowest stage** in your pipeline
3. **Survey the team** â€” What's frustrating about content production?
4. **Benchmark competitors** â€” How often do they update?
5. **Propose 1 tool/process improvement** with ROI estimate

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# 1B.7 Economy Health Check

## Why It Matters

Game economies are living systems. Over years, inflation creeps in, sinks become inadequate, early-game tuning clashes with late-game reality, and monetization friction points shift. An unhealthy economy drives away new players, frustrates veterans, and leaves money on the table. Regular health checks prevent slow decay.

## Framework: Currency Flow Analysis

### Soft Currency

| Metric | Current State | Healthy Range | Status |
|--------|---------------|---------------|--------|
| Daily earn rate (median) | | | ðŸŸ¢ðŸŸ¡ðŸ”´ |
| Daily earn rate (90th percentile) | | | ðŸŸ¢ðŸŸ¡ðŸ”´ |
| Primary sinks | | | |
| Sink adequacy | | | ðŸŸ¢ðŸŸ¡ðŸ”´ |
| Inflation rate (veteran stockpiles) | | <10%/year | ðŸŸ¢ðŸŸ¡ðŸ”´ |
| New player friction | | | ðŸŸ¢ðŸŸ¡ðŸ”´ |

### Hard Currency

| Metric | Current State | Healthy Range | Status |
|--------|---------------|---------------|--------|
| Free earn rate | | | |
| Primary purchase drivers | | | |
| Conversion friction points | | | |
| Value perception (surveys) | | | |

### Premium Items

| Category | Revenue % | Growth Trend | Notes |
|----------|-----------|--------------|-------|
| Consumables | | â†‘â†“â†’ | |
| Permanent unlocks | | â†‘â†“â†’ | |
| Cosmetics | | â†‘â†“â†’ | |
| Time savers | | â†‘â†“â†’ | |
| Gacha/lootboxes | | â†‘â†“â†’ | |
| Battle pass/subscription | | â†‘â†“â†’ | |

## Framework: Economy Red Flags

| Red Flag | Threshold | Your Status | Action |
|----------|-----------|-------------|--------|
| Veterans hoarding currency | >30 days of spend stockpiled | | New sinks needed |
| New players starving | <50% of needed currency earned D1-7 | | Early game rebalance |
| Single item dominates spend | >40% of sink | | Diversify sinks |
| Payer conversion dropping | >20% decline YoY | | Purchase flow audit |
| ARPPU declining | >10% decline YoY | | Offer value audit |
| Whales churning | Whale retention < average | | VIP program review |
| Negative sentiment on value | Reviews mention "greedy" | | Perception problem |

## Framework: Monetization Funnel Analysis

| Stage | Conversion Rate | Benchmark | Gap |
|-------|-----------------|-----------|-----|
| Install â†’ Tutorial complete | | | |
| Tutorial â†’ D1 active | | | |
| D1 â†’ First store visit | | | |
| Store visit â†’ First purchase | | | |
| First purchase â†’ Second purchase | | | |
| Payer â†’ Repeat payer (monthly) | | | |

**Biggest funnel gap:** _______________

## Framework: Offer Performance Analysis

| Offer Type | Shown/Month | Conversion Rate | Revenue | Trend |
|------------|-------------|-----------------|---------|-------|
| Starter pack | | | | â†‘â†“â†’ |
| Event bundle | | | | â†‘â†“â†’ |
| Daily deal | | | | â†‘â†“â†’ |
| Limited time | | | | â†‘â†“â†’ |
| Subscription | | | | â†‘â†“â†’ |
| Piggy bank/accumulator | | | | â†‘â†“â†’ |

**Best performing offer:** _______________

**Worst performing offer:** _______________

## Framework: Player Segment Economy Experience

| Segment | Currency Pain Points | Monetization Attitude | Opportunity |
|---------|---------------------|----------------------|-------------|
| New (<7 days) | | | |
| Developing (7-30 days) | | | |
| Established (30-180 days) | | | |
| Veteran (180+ days) | | | |
| Whale | | | |
| Lapsed returning | | | |

## Diagnostic Questions

| Question | Answer | Implication |
|----------|--------|-------------|
| How long can a veteran play without spending? | | Sink adequacy |
| What % of players hit a "paywall" feeling? | | Monetization friction |
| Are newer players monetizing better or worse than historical? | | Economy aging |
| What do players complain about re: monetization? | | Perception issues |
| When did we last rebalance the early game? | | New player experience |

## Checklist

- [ ] Currency sources and sinks mapped
- [ ] Inflation indicators checked
- [ ] New player economy experience audited
- [ ] Monetization funnel analyzed
- [ ] Offer performance reviewed
- [ ] Segment-specific issues identified
- [ ] Red flags addressed or acknowledged

## Tasks

1. **Map all currency sources and sinks** with rates
2. **Compare new player D1-7 economy** to 2 years ago
3. **Analyze veteran currency stockpiles** â€” inflation indicator
4. **Review monetization complaints** in reviews and support tickets
5. **Identify top 3 economy improvements** with expected impact

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# 1B.8 Team Capacity vs. Maintenance Load

## Why It Matters

Mature games carry maintenance burden: bug fixes, SDK updates, platform compliance, server costs, community management, live ops operation. If maintenance consumes all capacity, no room remains for improvement. Understanding your true available capacity for new work enables realistic planning.

## Framework: Capacity Allocation Breakdown

### Current State

| Activity Category | Hours/Week | % of Total | Trend |
|-------------------|------------|------------|-------|
| **Maintenance** | | | |
| - Bug fixes | | | â†‘â†“â†’ |
| - SDK/platform updates | | | â†‘â†“â†’ |
| - Server/infrastructure | | | â†‘â†“â†’ |
| - Technical debt interest | | | â†‘â†“â†’ |
| **Live Ops Operation** | | | |
| - Event execution | | | â†‘â†“â†’ |
| - Content deployment | | | â†‘â†“â†’ |
| - Monitoring/response | | | â†‘â†“â†’ |
| **Support** | | | |
| - Customer service | | | â†‘â†“â†’ |
| - Community management | | | â†‘â†“â†’ |
| **New Development** | | | |
| - Features | | | â†‘â†“â†’ |
| - Content creation | | | â†‘â†“â†’ |
| - Improvements | | | â†‘â†“â†’ |
| **Overhead** | | | |
| - Meetings | | | â†‘â†“â†’ |
| - Planning | | | â†‘â†“â†’ |
| - Admin | | | â†‘â†“â†’ |
| **Total** | | 100% | |

### Health Indicators

| Ratio | Your Value | Healthy Range | Status |
|-------|------------|---------------|--------|
| New development % | | >40% | ðŸŸ¢ðŸŸ¡ðŸ”´ |
| Maintenance % | | <30% | ðŸŸ¢ðŸŸ¡ðŸ”´ |
| Overhead % | | <15% | ðŸŸ¢ðŸŸ¡ðŸ”´ |

## Framework: Maintenance Burden Trend

| Period | Maintenance Hours/Week | New Dev Hours/Week | Ratio |
|--------|----------------------|-------------------|-------|
| 2 years ago | | | |
| 1 year ago | | | |
| 6 months ago | | | |
| Current | | | |
| Projected (6 months) | | | |

**Trend diagnosis:**
```
_______________________________________________________________________________
```

## Framework: Role-Specific Capacity

| Role | Total Hours/Week | Maintenance | Live Ops | New Dev | Available |
|------|------------------|-------------|----------|---------|-----------|
| Engineering | | | | | |
| Design | | | | | |
| Art | | | | | |
| QA | | | | | |
| Production | | | | | |
| Community | | | | | |
| Analytics | | | | | |
| **Total** | | | | | |

## Framework: Maintenance Reduction Opportunities

| Opportunity | Current Cost | Potential Savings | Investment Required | ROI Timeline |
|-------------|--------------|-------------------|--------------------| -------------|
| Automate testing | | | | |
| Better monitoring | | | | |
| Improve code quality | | | | |
| Reduce feature count | | | | |
| Better tools | | | | |
| Outsource | | | | |

## Framework: Team Size vs. Game Complexity

As games age, this question becomes critical: Is the team sized for the game's current complexity?

| Factor | Complexity Score (1-5) |
|--------|----------------------|
| Number of major systems | |
| Content volume | |
| Platform count | |
| Localization count | |
| Live ops intensity | |
| Technical debt level | |
| **Total Complexity** | /30 |

| Complexity Range | Minimum Sustainable Team | Your Team | Gap |
|------------------|-------------------------|-----------|-----|
| 1-10 (Simple) | 2-4 FTE | | |
| 11-18 (Medium) | 5-10 FTE | | |
| 19-24 (Complex) | 10-20 FTE | | |
| 25-30 (Very Complex) | 20+ FTE | | |

## Diagnostic Questions

| Question | Answer | Implication |
|----------|--------|-------------|
| How many "interrupt" tasks happen weekly? | | Predictability problem |
| What's the ratio of planned vs. unplanned work? | | Stability indicator |
| How often do we say "we don't have capacity"? | | Team sized wrong |
| What work is being neglected? | | Priority clarity |
| Are people working sustainable hours? | | Burnout risk |

## Checklist

- [ ] Current capacity allocation documented
- [ ] Maintenance burden trend analyzed
- [ ] Role-specific capacity mapped
- [ ] Team size vs. complexity assessed
- [ ] Reduction opportunities identified
- [ ] Sustainable pace confirmed or flagged

## Tasks

1. **Track actual time** for 2-4 weeks across all categories
2. **Calculate maintenance trend** over past 2 years
3. **Identify the biggest maintenance time sinks**
4. **Propose 2 capacity-freeing initiatives** with ROI
5. **Assess team sizing** against game complexity

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# 1B.9 Competitive Position Reassessment

## Why It Matters

The market doesn't stand still. Competitors launch, evolve, and die. Player expectations shift. What differentiated you 5 years ago may be table stakes today. Regular competitive assessment reveals threats, opportunities, and whether your positioning still makes sense.

## Framework: Competitive Landscape Update

### Direct Competitors (Same genre, same audience)

| Competitor | Status | Trend | What Changed Since Launch | Threat Level |
|------------|--------|-------|---------------------------|--------------|
| | Active/Declining/Dead | â†‘â†“â†’ | | High/Med/Low |
| | | | | |
| | | | | |
| | | | | |

### New Entrants (Since your launch)

| New Competitor | Launch Date | Positioning | Taking Share From You? |
|----------------|-------------|-------------|----------------------|
| | | | Yes/No/Unknown |
| | | | |
| | | | |

### Market Shifts

| Shift | Impact on You | Response Needed |
|-------|---------------|-----------------|
| Genre trends | | |
| Platform changes | | |
| Monetization norms | | |
| Feature expectations | | |
| UA/discovery changes | | |

## Framework: Feature Benchmark Update

| Feature | 2+ Years Ago | Now | Your Status | Priority |
|---------|--------------|-----|-------------|----------|
| | Table stakes/Differentiator/N/A | Table stakes/Differentiator/N/A | Have/Don't Have | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |

**Features that became table stakes since launch:**
```
_______________________________________________________________________________
```

**New potential differentiators:**
```
_______________________________________________________________________________
```

## Framework: Positioning Erosion Assessment

| Positioning Element | At Launch | Now | Still Valid? |
|--------------------|-----------|-----|--------------|
| Key differentiator | | | Yes/No/Partially |
| Target audience | | | Yes/No/Partially |
| Value proposition | | | Yes/No/Partially |
| Price positioning | | | Yes/No/Partially |

**Positioning erosion diagnosis:**
```
_______________________________________________________________________________
```

## Framework: Competitive Response Options

| Situation | Response Options |
|-----------|------------------|
| New strong competitor | Differentiate harder, niche down, or concede segment |
| Competitor copied your features | Innovate next, or compete on execution |
| Market expectations raised | Invest to keep pace, or accept decline |
| Competitor declined/died | Capture their audience |
| New market opportunity | Pivot or expand |

**Our competitive situation:** _______________

**Our strategic response:** _______________

## Framework: Player Switching Analysis

Why do players leave for competitors?

| Competitor They Leave For | What They Get There | What We Lack |
|--------------------------|---------------------|--------------|
| | | |
| | | |
| | | |

Why do players come FROM competitors?

| Competitor They Leave | What We Offer | How to Strengthen |
|----------------------|---------------|-------------------|
| | | |
| | | |

## Diagnostic Questions

| Question | Answer | Implication |
|----------|--------|-------------|
| When did we last deeply analyze competitors? | | Potential blind spots |
| What features have competitors added that we lack? | | Parity gaps |
| Are new games in our genre outperforming us? | | Market share risk |
| Has our genre grown or shrunk? | | Market opportunity |
| Do players compare us to different games than at launch? | | Positioning shift |

## Checklist

- [ ] Competitive landscape updated
- [ ] New entrants identified and assessed
- [ ] Feature benchmarks refreshed
- [ ] Positioning validity assessed
- [ ] Competitive response chosen
- [ ] Player switching patterns understood

## Tasks

1. **Update competitor list** â€” Who's relevant now?
2. **Play 2 competitors** for 2+ hours each â€” What's changed?
3. **Read competitor reviews** â€” What do their players love/hate?
4. **Compare download/revenue trends** â€” Who's winning?
5. **Identify 1 threat and 1 opportunity** from competitive analysis

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# 1B.10 Institutional Knowledge Audit

## Why It Matters

Over 8 years, knowledge accumulates in people's heads, not documents. Original developers leave. Decisions made years ago affect code today with no record of why. Critical systems are understood by one person. When institutional knowledge is lost, teams repeat mistakes, break things, and waste time rediscovering what was already known.

## Framework: Knowledge Risk Assessment

### Critical Systems Knowledge Map

| System/Area | Primary Expert | Backup Expert | Documentation Level | Bus Factor Risk |
|-------------|----------------|---------------|--------------------|--------------------|
| | | | None/Partial/Good | High/Med/Low |
| | | | | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |
| | | | | |

**Bus Factor:** How many people would need to leave before critical knowledge is lost?

| Risk Level | Criteria | Systems in This Category |
|------------|----------|-------------------------|
| Critical | 1 person knows, no docs | |
| High | 1-2 people know, partial docs | |
| Medium | 2+ people know, good docs | |
| Low | Team-wide knowledge, excellent docs | |

## Framework: Documentation Inventory

| Document Type | Exists? | Current? | Accessible? | Quality |
|---------------|---------|----------|-------------|---------|
| Architecture overview | | | | |
| System design docs | | | | |
| API documentation | | | | |
| Economy design doc | | | | |
| Content guidelines | | | | |
| Onboarding guide | | | | |
| Runbooks (incidents) | | | | |
| Decision log | | | | |
| Historical context docs | | | | |

## Framework: Knowledge Preservation Priority

| Knowledge Area | Criticality | Current State | Priority | Action |
|----------------|-------------|---------------|----------|--------|
| | High/Med/Low | At risk/Okay | 1-5 | Document/Train/Record |
| | | | | |
| | | | | |
| | | | | |
| | | | | |

## Framework: "Why We Did It This Way" Archaeology

For mature games, understanding historical decisions is crucial. Create a living document:

| System/Decision | What | When | Why | Who Decided | Still Valid? |
|-----------------|------|------|-----|-------------|--------------|
| | | | | | Yes/No/Unknown |
| | | | | | |
| | | | | | |
| | | | | | |

## Framework: Knowledge Transfer Plan

### For At-Risk Knowledge

| Knowledge Area | Current Expert | Target Learners | Method | Timeline |
|----------------|----------------|-----------------|--------|----------|
| | | | Pair work/Doc/Video | |
| | | | | |
| | | | | |

### For New Team Members

| Onboarding Topic | Resource | Duration | Owner |
|------------------|----------|----------|-------|
| Game overview | | | |
| Architecture intro | | | |
| Development workflow | | | |
| Live ops process | | | |
| Key systems deep dive | | | |
| Historical context | | | |

**Current onboarding time to productivity:** _______________

**Target onboarding time:** _______________

## Diagnostic Questions

| Question | Answer | Implication |
|----------|--------|-------------|
| How long does it take a new hire to be productive? | | Knowledge accessibility |
| What breaks when key people take vacation? | | Single points of failure |
| How often do we rediscover lost knowledge? | | Documentation gaps |
| Can we explain why major decisions were made? | | Historical context |
| What would we lose if [key person] left tomorrow? | | Knowledge concentration |

## Checklist

- [ ] Critical systems mapped to knowledge holders
- [ ] Bus factor assessed
- [ ] Documentation inventory completed
- [ ] High-risk areas identified
- [ ] Knowledge transfer plans created
- [ ] Onboarding process documented
- [ ] Decision log started (if not existing)

## Tasks

1. **Map knowledge to people** â€” Who knows what?
2. **Identify single points of failure** â€” What breaks if they leave?
3. **Audit documentation** â€” What exists, what's current, what's missing?
4. **Start a decision log** â€” Even recording decisions going forward helps
5. **Schedule knowledge transfer** for highest-risk areas

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# 1B.11 Sunset Candidates List

## Why It Matters

Adding is easier than removing. But every feature, system, and content type carries ongoing cost. Mature games must actively prune to stay healthyâ€”freeing capacity, reducing complexity, and focusing on what matters. Identifying sunset candidates is the first step; executing sunsets requires planning.

## Framework: Sunset Candidate Identification

Consolidate candidates from previous audits:

### From Feature Usage Audit (1B.4)

| Feature | Usage | Maintenance Cost | Sunset Rationale |
|---------|-------|------------------|------------------|
| | | | |
| | | | |
| | | | |

### From Technical Debt Inventory (1B.5)

| System | Debt Level | Replacement vs. Remove | Sunset Rationale |
|--------|------------|----------------------|------------------|
| | | | |
| | | | |
| | | | |

### From Economy Health Check (1B.7)

| Economy Element | Issue | Sunset Rationale |
|-----------------|-------|------------------|
| | | |
| | | |

### From Competitive Analysis (1B.9)

| Feature | No Longer Differentiated | Sunset Rationale |
|---------|-------------------------|------------------|
| | | |
| | | |

## Framework: Sunset Impact Assessment

For each candidate, assess impact before deciding:

| Candidate | Players Affected | Revenue Impact | Effort to Remove | Dependencies | Risk |
|-----------|------------------|----------------|------------------|--------------|------|
| | % of DAU | $/month lost | S/M/L | | High/Med/Low |
| | | | | | |
| | | | | | |
| | | | | | |
| | | | | | |

## Framework: Sunset Decision Matrix

```
                     Low Player Impact
                           â”‚
        QUICK WINS         â”‚      EASY CLEANUP
   (Remove now,            â”‚    (Remove now,
    minimal communication) â”‚     simple announcement)
                           â”‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                           â”‚
        CAREFUL REMOVAL    â”‚      STRATEGIC DECISION
   (Worth removing but     â”‚    (High impactâ€”must
    plan communication)    â”‚     justify carefully)
                           â”‚
                     High Player Impact

    â—„â”€â”€â”€ Low Effort â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ High Effort â”€â”€â”€â–º
```

| Quadrant | Candidates | Approach |
|----------|------------|----------|
| **QUICK WINS** | | Just do it |
| **EASY CLEANUP** | | Brief announcement, remove |
| **CAREFUL REMOVAL** | | Communication plan, grace period |
| **STRATEGIC DECISION** | | Stakeholder review, data backup |

## Framework: Sunset Execution Plan

For approved sunset candidates:

| Candidate | Decision | Announcement Date | Grace Period | Removal Date | Owner |
|-----------|----------|-------------------|--------------|--------------|-------|
| | Approve/Reject/Defer | | | | |
| | | | | | |
| | | | | | |

### Sunset Communication Template

```
What: [Feature/system being removed]
Why: [Honest, player-friendly explanation]
When: [Removal date]
Impact: [What players lose]
Alternative: [What to do instead, if applicable]
Data: [What happens to their progress/items]
Feedback: [How to share concerns]
```

## Framework: Sunset Blockers

| Blocker Type | Description | Mitigation |
|--------------|-------------|------------|
| Player backlash | Vocal minority attachment | Data-driven communication, grace period |
| Revenue dependency | Feature drives significant revenue | Find alternative revenue first |
| Technical coupling | Deeply integrated, risky to remove | Staged decoupling plan |
| Stakeholder resistance | Someone loves this feature | Present data, get explicit approval |
| Compliance/legal | Contractual or legal requirement | Legal review |

## Diagnostic Questions

| Question | Answer | Implication |
|----------|--------|-------------|
| When did we last remove a major feature? | | Culture indicator |
| What's the oldest feature we've never touched? | | Archaeology needed |
| What features do new players never discover? | | Complexity problem |
| What do we maintain but never promote? | | Zombie features |
| What would happen if we just turned it off? | | Risk assessment |

## Checklist

- [ ] Sunset candidates consolidated from all audits
- [ ] Impact assessment completed for each
- [ ] Decision matrix placement done
- [ ] Sunset decisions made (approve/reject/defer)
- [ ] Execution plan created for approved sunsets
- [ ] Communication plan drafted
- [ ] Blockers identified and mitigated

## Tasks

1. **Consolidate all sunset candidates** from previous audits
2. **Assess impact** for each candidate
3. **Place in decision matrix**
4. **Get stakeholder approval** for top 3 sunset candidates
5. **Draft communication** for first planned sunset

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# 1B.12 Improvement Prioritization Framework

## Why It Matters

Mature games have infinite improvement opportunities and finite capacity. Without a rigorous prioritization framework, teams chase shiny objects, defer hard problems, and fail to move the metrics that matter. A structured approach ensures effort goes where it creates most value.

## Framework: Opportunity Inventory

Consolidate improvement opportunities from all audits:

| # | Opportunity | Source | Category | Effort | Impact Hypothesis |
|---|-------------|--------|----------|--------|-------------------|
| 1 | | 1B.__ | Feature/Tech/Content/Economy/Process | S/M/L/XL | |
| 2 | | | | | |
| 3 | | | | | |
| 4 | | | | | |
| 5 | | | | | |
| 6 | | | | | |
| 7 | | | | | |
| 8 | | | | | |
| 9 | | | | | |
| 10 | | | | | |

## Framework: ICE Scoring

**I**mpact Ã— **C**onfidence Ã— **E**ase = ICE Score

| Opportunity | Impact (1-10) | Confidence (1-10) | Ease (1-10) | ICE Score | Rank |
|-------------|---------------|-------------------|-------------|-----------|------|
| | | | | | |
| | | | | | |
| | | | | | |
| | | | | | |
| | | | | | |

**Scoring Guide:**

| Dimension | 1-3 | 4-6 | 7-10 |
|-----------|-----|-----|------|
| **Impact** | Minimal metric movement | Moderate improvement | Significant KPI improvement |
| **Confidence** | Guess/hope | Some data/precedent | Strong data/proven |
| **Ease** | XL effort, high risk | Medium effort, manageable | Quick win, low risk |

## Framework: RICE Scoring (Alternative)

**R**each Ã— **I**mpact Ã— **C**onfidence / **E**ffort = RICE Score

| Opportunity | Reach (users/month) | Impact (0.25-3) | Confidence (%) | Effort (person-months) | RICE Score |
|-------------|--------------------| ----------------|----------------|----------------------|------------|
| | | | | | |
| | | | | | |
| | | | | | |
| | | | | | |

**Impact Scale:**
- 3 = Massive (changes behavior significantly)
- 2 = High (notable improvement)
- 1 = Medium (some improvement)
- 0.5 = Low (minimal improvement)
- 0.25 = Minimal (barely noticeable)

## Framework: Prioritization Dimensions

Beyond ICE/RICE, consider strategic fit:

| Opportunity | Metric Impact | Strategic Alignment | Risk Level | Dependencies | Final Priority |
|-------------|---------------|---------------------|------------|--------------|----------------|
| | High/Med/Low | High/Med/Low | High/Med/Low | None/Some/Many | 1-5 |
| | | | | | |
| | | | | | |
| | | | | | |

## Framework: Priority Buckets

Sort opportunities into action categories:

| Bucket | Criteria | Opportunities | Action |
|--------|----------|---------------|--------|
| **Do Now** | High ICE, low risk, aligns with strategy | | Next sprint/cycle |
| **Plan** | High value but needs preparation | | Roadmap for next quarter |
| **Investigate** | High potential but low confidence | | Run experiment/research |
| **Backlog** | Moderate value, not urgent | | Keep visible, revisit |
| **Reject** | Low value or doesn't align | | Document why and close |

## Framework: Sequencing Considerations

| Consideration | Question | Impact on Sequence |
|---------------|----------|-------------------|
| **Dependencies** | Does A need to happen before B? | Sequence accordingly |
| **Learning** | Will this experiment inform other decisions? | Do earlier |
| **Seasonality** | Is there a time-sensitive window? | Schedule around events |
| **Team availability** | Who's needed and when are they free? | Resource-constrained |
| **Risk bundling** | Too many risky things at once? | Spread risk |

## Framework: Quarterly Roadmap Template

| Priority | Initiative | Goal/Hypothesis | Effort | Success Metric | Owner |
|----------|-----------|-----------------|--------|----------------|-------|
| 1 | | | | | |
| 2 | | | | | |
| 3 | | | | | |
| 4 | | | | | |
| 5 | | | | | |

**Total planned effort:** _______________ 

**Remaining capacity for unplanned:** _______________

## Diagnostic Questions

| Question | Answer | Implication |
|----------|--------|-------------|
| How do we currently prioritize? | | Process maturity |
| Do we have data to inform impact estimates? | | Confidence level |
| How often do priorities shift mid-quarter? | | Planning stability |
| Are we working on highest-value items? | | Alignment check |
| What's languishing in the backlog? | | Hidden important things |

## Checklist

- [ ] All improvement opportunities inventoried
- [ ] Scoring methodology chosen (ICE, RICE, or custom)
- [ ] All opportunities scored
- [ ] Strategic alignment assessed
- [ ] Priority buckets assigned
- [ ] Sequencing considered
- [ ] Quarterly roadmap drafted
- [ ] Stakeholders aligned on priorities

## Tasks

1. **Consolidate all opportunities** from Block 1B audits
2. **Score each** using your chosen methodology
3. **Review top 10** with stakeholders for alignment
4. **Create quarterly roadmap** based on capacity
5. **Communicate priorities** to full team

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# 1B.13 Stakeholder Realignment

## Why It Matters

Mature games accumulate stakeholders with different goals: revenue targets, player satisfaction, technical health, team wellbeing. Over time, these goals can diverge without explicit reconciliation. Before charting a new direction, ensure all stakeholders share understanding of current reality and agree on priorities.

## Framework: Stakeholder Map (Mature Game)

| Stakeholder | Their Primary Goal | How They Measure Success | Current Concerns |
|-------------|--------------------|-------------------------|------------------|
| Executive/Leadership | | | |
| Product Lead | | | |
| Engineering Lead | | | |
| Live Ops Lead | | | |
| Marketing/UA | | | |
| Community Manager | | | |
| Finance | | | |
| External (Publisher/Platform) | | | |

## Framework: Goal Alignment Assessment

| Goal | Stakeholder A | Stakeholder B | Stakeholder C | Aligned? |
|------|---------------|---------------|---------------|----------|
| Revenue growth | Priority: ___ | Priority: ___ | Priority: ___ | Yes/No |
| Retention improvement | Priority: ___ | Priority: ___ | Priority: ___ | Yes/No |
| Technical health | Priority: ___ | Priority: ___ | Priority: ___ | Yes/No |
| Player satisfaction | Priority: ___ | Priority: ___ | Priority: ___ | Yes/No |
| Team sustainability | Priority: ___ | Priority: ___ | Priority: ___ | Yes/No |
| New feature development | Priority: ___ | Priority: ___ | Priority: ___ | Yes/No |

**Misalignments to resolve:**
```
_______________________________________________________________________________
```

## Framework: Current Reality Briefing

Before seeking alignment on future direction, ensure shared understanding of present:

### Key Findings Summary (from Block 1B Audits)

| Area | Current Status | Trend | Key Insight |
|------|----------------|-------|-------------|
| Vision alignment | ðŸŸ¢ðŸŸ¡ðŸ”´ | â†‘â†“â†’ | |
| Metrics health | ðŸŸ¢ðŸŸ¡ðŸ”´ | â†‘â†“â†’ | |
| Audience | ðŸŸ¢ðŸŸ¡ðŸ”´ | â†‘â†“â†’ | |
| Feature health | ðŸŸ¢ðŸŸ¡ðŸ”´ | â†‘â†“â†’ | |
| Technical debt | ðŸŸ¢ðŸŸ¡ðŸ”´ | â†‘â†“â†’ | |
| Content pipeline | ðŸŸ¢ðŸŸ¡ðŸ”´ | â†‘â†“â†’ | |
| Economy | ðŸŸ¢ðŸŸ¡ðŸ”´ | â†‘â†“â†’ | |
| Team capacity | ðŸŸ¢ðŸŸ¡ðŸ”´ | â†‘â†“â†’ | |
| Competitive position | ðŸŸ¢ðŸŸ¡ðŸ”´ | â†‘â†“â†’ | |
| Knowledge health | ðŸŸ¢ðŸŸ¡ðŸ”´ | â†‘â†“â†’ | |

### Top 3 Risks
1. 
2. 
3. 

### Top 3 Opportunities
1. 
2. 
3. 

## Framework: Decision Rights Clarity

For mature games, decision rights often become unclear. Re-establish:

| Decision Type | Who Decides | Who Consults | Who's Informed |
|---------------|-------------|--------------|----------------|
| Major feature adds | | | |
| Feature sunset | | | |
| Economy changes | | | |
| Event calendar | | | |
| Technical investments | | | |
| Team changes | | | |
| Budget allocation | | | |
| Kill/sunset game | | | |

## Framework: Scenario Alignment

Test alignment with hypothetical scenarios:

| Scenario | Stakeholder A Response | Stakeholder B Response | Aligned? |
|----------|----------------------|----------------------|----------|
| Metrics decline 20%â€”cut costs or invest to fix? | | | |
| Competitor launchesâ€”copy features or differentiate? | | | |
| Major tech debtâ€”delay features to fix? | | | |
| Team burnout riskâ€”reduce output or add people? | | | |
| Revenue short of targetâ€”more aggressive monetization? | | | |

## Framework: Realignment Commitments

After discussion, document explicit agreements:

| Topic | Agreement | Stakeholders Committed |
|-------|-----------|----------------------|
| Primary goal for next 6 months | | |
| Acceptable metric ranges | | |
| Investment vs. harvest stance | | |
| Team sustainability commitment | | |
| Decision-making process | | |

## Checklist

- [ ] All relevant stakeholders identified
- [ ] Current goals and priorities documented for each
- [ ] Misalignments surfaced
- [ ] Current reality briefing prepared
- [ ] Decision rights clarified
- [ ] Scenario alignment tested
- [ ] Explicit commitments documented

## Tasks

1. **Map all stakeholders** and their primary concerns
2. **Prepare current reality summary** from Block 1B audits
3. **Conduct alignment conversations** individually first
4. **Identify misalignments** requiring group resolution
5. **Facilitate alignment session** and document commitments

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# 1B.14 Realignment Workshop

## Why It Matters

The Block 1B audit surfaces reality. The realignment workshop creates shared commitment to act on it. Without this explicit moment of alignment, insights get filed and forgotten, and the team continues as before. This workshop is the bridge between diagnosis and action.

## Framework: Workshop Agenda

**Duration:** 3-4 hours (or split across sessions)

**Participants:** All key stakeholders identified in 1B.13

| Time | Activity | Output |
|------|----------|--------|
| 15 min | Context: Why are we here? What's at stake? | Shared urgency |
| 30 min | Current Reality: Present audit findings | Shared understanding |
| 20 min | Q&A and Clarification | Address misunderstandings |
| 30 min | Vision check: Is our direction still right? | Vision confirmed or updated |
| 30 min | Priority discussion: What matters most now? | Aligned priorities |
| 30 min | Capacity reality: What can we actually do? | Realistic expectations |
| 20 min | Decisions: What are we committing to? | Explicit commitments |
| 15 min | Next steps: Who does what by when? | Action plan |

## Framework: Pre-Workshop Preparation

### Materials to Prepare

- [ ] Executive summary of Block 1B findings (2 pages max)
- [ ] Key metrics trends (visual)
- [ ] Top risks and opportunities
- [ ] Prioritized improvement list
- [ ] Capacity constraints summary
- [ ] Competitor update (if significant changes)

### Pre-Workshop Questions to Seed

Send to participants 48+ hours before:

1. What's the single biggest threat to this game's future?
2. What's the biggest opportunity we're not pursuing?
3. If we could only do ONE thing next quarter, what should it be?
4. What are we doing that we should stop?

## Framework: Discussion Guide

### Section 1: Current Reality Acceptance

**Questions to drive discussion:**
- Does this data match your intuition? Where are you surprised?
- What are we not measuring that we should be?
- What's the most uncomfortable truth here?

**Success criteria:** All participants acknowledge current state without blame or denial

### Section 2: Direction Validation

**Questions to drive discussion:**
- Given what we now know, is our current direction right?
- Should we continue, evolve, or pivot?
- What would success look like in 12 months?

**Success criteria:** Explicit decision on strategic direction

### Section 3: Priority Alignment

**Questions to drive discussion:**
- Of all the improvements identified, which 3 matter most?
- What are we willing to NOT do to focus?
- What are we willing to sunset or deprioritize?

**Success criteria:** Ranked priorities with stakeholder buy-in

### Section 4: Commitment

**Questions to drive discussion:**
- What specifically are we committing to deliver?
- What resources will we allocate?
- How will we measure success?
- What will we stop doing to make room?

**Success criteria:** Written commitments with owners

## Framework: Alignment Confirmation

At workshop end, confirm alignment:

### We agree on:

| Topic | Agreement |
|-------|-----------|
| Current state assessment | |
| Strategic direction | |
| Top 3 priorities | |
| What we're stopping | |
| Resource allocation | |
| Success metrics | |
| Review cadence | |

### Each participant confirms:

| Name | Role | Signature/Confirmation | Date |
|------|------|----------------------|------|
| | | | |
| | | | |
| | | | |
| | | | |

## Framework: Post-Workshop Actions

| Action | Owner | Due Date | Status |
|--------|-------|----------|--------|
| Distribute workshop summary | | | |
| Update roadmap based on decisions | | | |
| Communicate changes to full team | | | |
| Schedule quarterly review | | | |
| Begin work on Priority #1 | | | |
| Initiate approved sunsets | | | |

## Framework: Ongoing Review Cadence

| Review Type | Frequency | Participants | Focus |
|-------------|-----------|--------------|-------|
| Metrics review | Weekly | Product, Analytics | KPI trends |
| Sprint review | Bi-weekly | Core team | Progress, blockers |
| Live ops review | Weekly | Live ops team | Event performance |
| Strategic review | Monthly | Leads | Direction, priorities |
| Full health audit | Quarterly | All stakeholders | Repeat Block 1B |

## Checklist

- [ ] Workshop scheduled with all stakeholders
- [ ] Pre-workshop materials distributed
- [ ] Pre-workshop questions sent
- [ ] Facilitation planned
- [ ] Workshop conducted
- [ ] Decisions documented
- [ ] Commitments captured
- [ ] Post-workshop actions assigned
- [ ] Review cadence established

## Tasks

1. **Schedule the workshop** with all key stakeholders
2. **Prepare materials** summarizing Block 1B findings
3. **Send pre-work** to participants
4. **Facilitate the session** using the agenda
5. **Document outcomes** and distribute within 24 hours
6. **Follow up** on action items

## Notes

```
_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________

_______________________________________________________________________________
```

---

# Block 1B Summary

## Health Assessment Checklist

Before proceeding to Block 2B (Live Ops Planning & Optimization), confirm:

| Assessment Area | Complete? | Key Finding | Action Needed |
|-----------------|-----------|-------------|---------------|
| Vision Drift Assessment | | | |
| Metrics Audit | | | |
| Audience Evolution | | | |
| Feature Usage Audit | | | |
| Technical Debt Inventory | | | |
| Content Pipeline Efficiency | | | |
| Economy Health Check | | | |
| Team Capacity vs. Load | | | |
| Competitive Position | | | |
| Institutional Knowledge | | | |
| Sunset Candidates | | | |
| Improvement Prioritization | | | |
| Stakeholder Realignment | | | |
| Realignment Workshop | | | |

## Key Outputs from Block 1B

| Output | Location | Owner |
|--------|----------|-------|
| Updated vision statement | | |
| Metrics health dashboard | | |
| Feature health matrix | | |
| Technical debt priority list | | |
| Sunset roadmap | | |
| Prioritized improvement list | | |
| Stakeholder commitment document | | |

## Red Flags Requiring Immediate Attention

- [ ] Metrics declining with no clear cause
- [ ] Key person dependencies with no mitigation
- [ ] Technical debt blocking feature work
- [ ] Team capacity <40% available for new development
- [ ] Vision fundamentally misaligned with current reality
- [ ] No recent feature sunset (>2 years)
- [ ] Institutional knowledge concentrated in departing employees

## Recommended Review Cadence

| Activity | Frequency |
|----------|-----------|
| Metrics review | Weekly |
| Feature usage check | Monthly |
| Full Block 1B audit | Quarterly |
| Vision/strategy review | Annually |

## Next Steps

Based on Block 1B findings, proceed to:

**Block 2B: Live Ops Planning & Optimization** â€” Improving event cadence, content velocity, and operational efficiency for mature games

OR

**Block 2A: Planning & Milestones** â€” If Block 1B revealed need for major new initiative

---

*"A smaller, polished gem shines brighter than a rough, uncut diamond."*

---
